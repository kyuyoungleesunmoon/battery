"""
Phase 5 ê²°ê³¼ë¥¼ train.ipynbì— ì‚½ì…í•©ë‹ˆë‹¤.
"""
import json
import pandas as pd

# ê²°ê³¼ íŒŒì¼ ë¡œë“œ (í…ìŠ¤íŠ¸ íŒŒì‹± ëŒ€ì‹  í•˜ë“œì½”ë”©ëœ ìš”ì•½ ì •ë³´ ì‚¬ìš© ë˜ëŠ” íŒŒì‹±)
# ì—¬ê¸°ì„œëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš©ì„ ì°¸ì¡°í•˜ì—¬ ì§ì ‘ ì…€ ë‚´ìš©ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

with open('train.ipynb', 'r', encoding='utf-8') as f:
    nb = json.load(f)

def make_md(lines):
    return {"cell_type": "markdown", "metadata": {}, "source": [l + "\n" for l in lines]}

def make_code(lines):
    return {"cell_type": "code", "execution_count": None, "metadata": {}, "outputs": [], "source": [l + "\n" for l in lines]}

cells = []

# Phase 5 í—¤ë”
cells.append(make_md([
    "# Phase 5: ëª¨ë¸ í•™ìŠµ ë° í‰ê°€",
    "",
    "Phase 4ì—ì„œ ì¤€ë¹„í•œ 4ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ì…‹ì— ëŒ€í•´ ë‹¤ìŒ ëª¨ë¸ë“¤ì„ í•™ìŠµí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.",
    "",
    "1. **Linear Regression** (Baseline, RobustScaler)",
    "2. **SVR** (Support Vector Regression, RobustScaler)",
    "3. **Random Forest** (Ensemble, No Scaler)",
    "4. **XGBoost** (Boosting, No Scaler)",
    "5. **LightGBM** (Boosting, No Scaler)",
    "",
    "í‰ê°€ì§€í‘œ: **RMSE** (Root Mean Squared Error), **RÂ²** (Coefficient of Determination), **MAPE**"
]))

# ì½”ë“œ ì…€ (ëª¨ë¸ë§)
cells.append(make_code([
    "# ============================================================",
    "# Phase 5. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ Loop",
    "# ============================================================",
    "import time",
    "from sklearn.linear_model import LinearRegression",
    "from sklearn.svm import SVR",
    "from sklearn.ensemble import RandomForestRegressor",
    "import xgboost as xgb",
    "import lightgbm as lgb",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error",
    "",
    "# ëª¨ë¸ ì •ì˜",
    "models = {",
    "    'LinearReg': LinearRegression(),",
    "    'SVR': SVR(C=1.0, epsilon=0.01),",
    "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1),",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1, verbose=-1)",
    "}",
    "",
    "results_list = []",
    "",
    "print('ğŸš€ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì‹œì‘...')",
    "print('=' * 80)",
    "",
    "for s_name, data in scenario_datasets.items():",
    "    X_tr = data['X_train']",
    "    X_te = data['X_test']",
    "    feats = data['features']",
    "    ",
    "    # RobustScaler (ì„ í˜• ëª¨ë¸ìš©)",
    "    scaler = RobustScaler()",
    "    X_tr_scaled = pd.DataFrame(scaler.fit_transform(X_tr), columns=feats, index=X_tr.index)",
    "    X_te_scaled = pd.DataFrame(scaler.transform(X_te), columns=feats, index=X_te.index)",
    "    ",
    "    print(f'\\n[{s_name}] (í”¼ì²˜ {len(feats)}ê°œ)')",
    "    print('-' * 60)",
    "    ",
    "    for m_name, model in models.items():",
    "        # ìŠ¤ì¼€ì¼ë§ ì ìš© ì—¬ë¶€",
    "        if m_name in ['LinearReg', 'SVR']:",
    "            X_train_curr, X_test_curr = X_tr_scaled, X_te_scaled",
    "        else:",
    "            X_train_curr, X_test_curr = X_tr, X_te",
    "            ",
    "        start = time.time()",
    "        model.fit(X_train_curr, y_train)",
    "        train_time = time.time() - start",
    "        ",
    "        y_pred = model.predict(X_test_curr)",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)",
    "        r2 = r2_score(y_test, y_pred)",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)",
    "        ",
    "        print(f'{m_name:12s} | RMSE={rmse:.4f}, R2={r2:.4f}, MAPE={mape:.4f} ({train_time:.2f}s)')",
    "        ",
    "        results_list.append({",
    "            'Scenario': s_name, 'Model': m_name,",
    "            'RMSE': rmse, 'R2': r2, 'MAPE': mape",
    "        })",
    "",
    "results_df = pd.DataFrame(results_list)"
]))

# ê²°ê³¼ ìš”ì•½ ë§ˆí¬ë‹¤ìš´
cells.append(make_md([
    "## 5-2. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”",
    "",
    "### ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„±ëŠ¥ ìš”ì•½",
    "",
    "| ì‹œë‚˜ë¦¬ì˜¤ | Best Model | RMSE | RÂ² | ë¹„ê³  |",
    "|---|---|---|---|---|",
    "| **S1 (Initial)** | LinearReg | 0.0355 | **0.0548** | ì˜ˆì¸¡ë ¥ ê±°ì˜ ì—†ìŒ |",
    "| **S2 (+4.2V)** | SVR | 0.0348 | **0.0948** | ì—¬ì „íˆ ë‚®ìŒ |",
    "| **S3 (+3.6V)** | RandomForest | 0.0350 | **0.0838** | ê°œì„  ì—†ìŒ |",
    "| **S4 (Full)** | **XGBoost** | **0.0246** | **0.5454** | **ìœ ì¼í•˜ê²Œ ìœ ì˜ë¯¸í•œ ì˜ˆì¸¡ ì„±ëŠ¥** |",
    "",
    "> **ê²°ë¡ **: ë°©ì „ ì¢…ì§€ ì „ì••(2.5V) ê´€ë ¨ ë°ì´í„°(`voltage_sag`, `v25_voltage`) ì—†ì´ëŠ” ë°°í„°ë¦¬ ìš©ëŸ‰ ì˜ˆì¸¡ì´ ë¶ˆê°€ëŠ¥í•¨."
]))

# ì‹œê°í™” ì½”ë“œ
cells.append(make_code([
    "# ============================================================",
    "# 5-2. ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”",
    "# ============================================================",
    "import matplotlib.pyplot as plt",
    "import seaborn as sns",
    "",
    "plt.figure(figsize=(14, 6))",
    "sns.barplot(data=results_df, x='Scenario', y='R2', hue='Model')",
    "plt.title('R2 Score Comparison by Scenario and Model', fontsize=14, fontweight='bold')",
    "plt.axhline(0, color='black', linewidth=0.5)",
    "plt.axhline(0.5, color='red', linestyle='--', label='R2=0.5')",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')",
    "plt.tight_layout()",
    "plt.show()"
]))

# í”¼ì²˜ ì¤‘ìš”ë„ ì½”ë“œ
cells.append(make_code([
    "# ============================================================",
    "# 5-3. Feature Importance (Scenario 4 - XGBoost)",
    "# ============================================================",
    "# S4 ë°ì´í„°ë¡œ XGBoost ì¬í•™ìŠµ ë° í”¼ì²˜ ì¤‘ìš”ë„ ì¶”ì¶œ",
    "xgb_best = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, n_jobs=-1)",
    "xgb_best.fit(scenario_datasets['S4_ALL']['X_train'], y_train)",
    "",
    "importances = xgb_best.feature_importances_",
    "feats = scenario_datasets['S4_ALL']['features']",
    "indices = np.argsort(importances)[::-1]",
    "",
    "plt.figure(figsize=(10, 8))",
    "plt.title('Feature Importance (Scenario 4 - XGBoost)', fontsize=14, fontweight='bold')",
    "plt.barh(range(len(indices)), importances[indices], align='center', color='teal')",
    "plt.yticks(range(len(indices)), [feats[i] for i in indices])",
    "plt.xlabel('Relative Importance')",
    "plt.gca().invert_yaxis()  # ìƒìœ„ í”¼ì²˜ê°€ ìœ„ë¡œ ì˜¤ê²Œ",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "print('ğŸ† Top 5 Features:')",
    "for i in range(5):",
    "    print(f'  {i+1}. {feats[indices[i]]:25s}: {importances[indices[i]]:.4f}')"
]))

cells.append(make_md([
    "### ğŸ”‘ í•µì‹¬ í”¼ì²˜ ë¶„ì„",
    "",
    "1. **`voltage_sag` (ì¤‘ìš”ë„ 0.39)**: ì´ˆê¸° ì „ì••ê³¼ 2.5V ë„ë‹¬ ì‹œì ì˜ ì „ì•• ì°¨ì´. ì••ë„ì ì¸ ì¤‘ìš”ë„ 1ìœ„.",
    "2. **`v25_voltage` (ì¤‘ìš”ë„ 0.13)**: ë°©ì „ ì¢…ì§€ ì „ì•• ìì²´ë„ ì¤‘ìš”.",
    "3. **`impedance_mean` (ì¤‘ìš”ë„ 0.10)**: ë‚´ë¶€ì €í•­ í‰ê· ë„ ê¸°ì—¬í•¨.",
    "",
    "> **ìµœì¢… ê²°ë¡ **: ë°°í„°ë¦¬ ìš©ëŸ‰ ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” **ì™„ì „ ë°©ì „ í…ŒìŠ¤íŠ¸(2.5V)**ê°€ í•„ìˆ˜ì ì´ë©°, ì´ ê³¼ì •ì—ì„œ ì–»ì–´ì§€ëŠ” ì „ì•• ê°•í•˜(`voltage_sag`)ê°€ ê°€ì¥ ê°•ë ¥í•œ ì˜ˆì¸¡ ì¸ìì…ë‹ˆë‹¤."
]))

# ë…¸íŠ¸ë¶ì— ì¶”ê°€
for cell in cells:
    nb['cells'].append(cell)

with open('train.ipynb', 'w', encoding='utf-8') as f:
    json.dump(nb, f, ensure_ascii=False, indent=1)

print(f"ì™„ë£Œ! ì´ {len(nb['cells'])}ê°œ ì…€ ({len(cells)}ê°œ Phase 5 ì…€ ì¶”ê°€)")
