import json
import os

NOTEBOOK_PATH = "train.ipynb"

def create_markdown_cell(source):
    return {
        "cell_type": "markdown",
        "metadata": {},
        "source": [line + "\n" for line in source]
    }

def create_code_cell(source):
    return {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [line + "\n" for line in source]
    }

def main():
    if not os.path.exists(NOTEBOOK_PATH):
        print(f"Error: {NOTEBOOK_PATH} not found.")
        return

    with open(NOTEBOOK_PATH, "r", encoding="utf-8") as f:
        nb = json.load(f)

    # 1. Remove Any existing Optuna tuning cells if they are in the wrong place
    # We marks cells by content to be safe.
    new_cells_list = []
    for cell in nb['cells']:
        source_text = "".join(cell['source'])
        if "7-1. Teacher Model (XGBoost) Hyperparameter Tuning" in source_text or \
           "import optuna" in source_text or \
           "study.optimize(objective, n_trials=20)" in source_text or \
           "7-2. ìµœì í™”ëœ Teacher ëª¨ë¸ í•™ìŠµ ë° Soft Label ìƒì„±" in source_text:
            continue
        new_cells_list.append(cell)
    
    nb['cells'] = new_cells_list

    # 2. Find the index of the Phase 7 header again
    phase_7_index = -1
    for i, cell in enumerate(nb['cells']):
        if cell['cell_type'] == 'markdown':
            source_text = "".join(cell['source'])
            if "Phase 7" in source_text and ("Teacher-Student" in source_text or "Knowledge Distillation" in source_text) and "ê²°ë¡ " not in source_text:
                phase_7_index = i
                break

    if phase_7_index == -1:
        print("Error: Could not find Phase 7 header. Appending to end.")
        phase_7_index = len(nb['cells']) - 1

    print(f"Injecting Optuna cells after index {phase_7_index}")

    # 3. Define Optuna cells
    optuna_cells = [
        create_markdown_cell([
            "### 7-1. Teacher Model (XGBoost) Hyperparameter Tuning with Optuna",
            "",
            "ê³ ì„±ëŠ¥ Teacher ëª¨ë¸ í™•ë³´ë¥¼ ìœ„í•´ Optunaë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.",
            "Teacher ëª¨ë¸ì€ **S4 (ì „ì²´ ë°ì´í„°)** ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
        ]),
        create_code_cell([
            "import optuna",
            "import xgboost as xgb",
            "from sklearn.metrics import mean_squared_error",
            "from sklearn.model_selection import train_test_split",
            "",
            "# Optuna ë¡œê¹… ë ˆë²¨ ì¡°ì •",
            "optuna.logging.set_verbosity(optuna.logging.WARNING)",
            "",
            "def objective(trial):",
            "    # S4 ë°ì´í„°ì…‹ ì‚¬ìš© (ëª¨ë“  í”¼ì²˜)",
            "    X_train_s4 = scenario_datasets['S4_ALL']['X_train']",
            "    y_train_s4 = scenario_datasets['S4_ALL']['y_train']",
            "    ",
            "    # ê²€ì¦ì…‹ ë¶„ë¦¬",
            "    X_tr, X_val, y_tr, y_val = train_test_split(X_train_s4, y_train_s4, test_size=0.2, random_state=42)",
            "    ",
            "    param = {",
            "        'objective': 'reg:squarederror',",
            "        'verbosity': 0,",
            "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),",
            "        'max_depth': trial.suggest_int('max_depth', 3, 10),",
            "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),",
            "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),",
            "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),",
            "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),",
            "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),",
            "        'random_state': 42",
            "    }",
            "    ",
            "    model = xgb.XGBRegressor(**param)",
            "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)",
            "    ",
            "    preds = model.predict(X_val)",
            "    rmse = np.sqrt(mean_squared_error(y_val, preds))",
            "    return rmse",
            "",
            "print('ğŸš€ Optuna ìµœì í™” ì‹œì‘...')",
            "study = optuna.create_study(direction='minimize')",
            "study.optimize(objective, n_trials=20)",
            "",
            "print('âœ… ìµœì  íŒŒë¼ë¯¸í„°:', study.best_params)",
            "print('âœ… Best RMSE:', study.best_value)"
        ]),
        create_markdown_cell([
            "### 7-2. ìµœì í™”ëœ Teacher ëª¨ë¸ í•™ìŠµ ë° Soft Label ìƒì„±",
            "",
            "Optunaë¡œ ì°¾ì€ ìµœì  íŒŒë¼ë¯¸í„°ë¡œ Teacher ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµí•˜ê³ , Soft Target(ì˜ˆì¸¡ê°’)ì„ ìƒì„±í•©ë‹ˆë‹¤."
        ]),
        create_code_cell([
            "# ìµœì  íŒŒë¼ë¯¸í„°ë¡œ Teacher ëª¨ë¸ ì¬í•™ìŠµ (S4 ì „ì²´ ë°ì´í„°)",
            "best_params = study.best_params",
            "best_params['objective'] = 'reg:squarederror'",
            "best_params['random_state'] = 42",
            "",
            "teacher_model_opt = xgb.XGBRegressor(**best_params)",
            "teacher_model_opt.fit(scenario_datasets['S4_ALL']['X_train'], scenario_datasets['S4_ALL']['y_train'])",
            "",
            "# ì „ì²´ Train ë°ì´í„°ì— ëŒ€í•œ Teacher ì˜ˆì¸¡ê°’ ìƒì„± (Soft Labels)",
            "# Studentê°€ í•™ìŠµí•  ë•Œ ì°¸ê³ í•  'ì •ì œëœ ì§€ì‹'ì…ë‹ˆë‹¤.",
            "y_teacher_pred = teacher_model_opt.predict(X_train[scenario4_features])",
            "",
            "print('âœ… ìµœì í™”ëœ Teacher ëª¨ë¸ í•™ìŠµ ë° Soft Label ìƒì„± ì™„ë£Œ')",
            "print(f'Soft Label Sample: {y_teacher_pred[:5]}')"
        ])
    ]

    # 4. Insert cells
    insert_pos = phase_7_index + 1
    for cell in reversed(optuna_cells):
        nb['cells'].insert(insert_pos, cell)

    with open(NOTEBOOK_PATH, "w", encoding="utf-8") as f:
        json.dump(nb, f, ensure_ascii=False, indent=1)

    print(f"Successfully placed Optuna cells after index {phase_7_index}")

if __name__ == "__main__":
    main()
