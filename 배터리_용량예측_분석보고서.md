# 🔋 중고 배터리 셀 용량(Capacity) 예측 모델 개발 보고서

> **프로젝트**: 중고 배터리 셀의 초기 측정 데이터 기반 실제 방전 용량 예측  
> **작성일**: 2026년 2월 21일  
> **데이터**: 1,040개 배터리 셀 (BS-LSBAT-S240629 배치)  
> **분석 환경**: Python 3.14, XGBoost 3.2, LightGBM 4.6, Optuna 4.7

---

## 목차

1. [분석 개요 (Executive Summary)](#1-분석-개요-executive-summary)
2. [데이터 탐색 및 현황 (Phase 1)](#2-데이터-탐색-및-현황-phase-1)
3. [파생변수 설계 (Phase 2)](#3-파생변수-설계-phase-2)
4. [데이터 전처리 및 피처 선택 (Phase 3)](#4-데이터-전처리-및-피처-선택-phase-3)
5. [측정 시나리오 설계 (Phase 3-4)](#5-측정-시나리오-설계-phase-3-4)
6. [모델 학습 및 성능 비교 (Phase 5)](#6-모델-학습-및-성능-비교-phase-5)
7. [Knowledge Distillation 실험 (Phase 7)](#7-knowledge-distillation-실험-phase-7)
8. [성능 고도화 실험 (Phase 8)](#8-성능-고도화-실험-phase-8)
9. [S1 집중 개선 실험 (Phase 9)](#9-s1-집중-개선-실험-phase-9)
10. [KD 정보채널 보완 (Phase 10)](#10-kd-정보채널-보완-phase-10)
11. [종합 결론 및 제언](#11-종합-결론-및-제언)
12. [부록: 기술 상세](#12-부록-기술-상세)

---

## 1. 분석 개요 (Executive Summary)

### 1.1 프로젝트 배경

중고 배터리 셀의 잔존 용량(Capacity)을 **비파괴적 초기 측정**만으로 빠르게 추정하는 것은 배터리 재사용·재활용 시장에서 핵심적인 과제입니다. 현재 정확한 용량 측정을 위해서는 **완전 충방전 사이클**(4.2V → 2.5V)이 필요하며, 이는 셀당 수 시간의 시간과 전력 비용이 소요됩니다.

본 프로젝트는 **부분적 측정 데이터만으로 용량을 예측**할 수 있는 머신러닝 모델을 개발하여, 측정 비용을 절감하면서도 신뢰할 수 있는 용량 추정이 가능한지를 검증합니다.

### 1.2 핵심 결과 요약

| 항목 | 결과 |
|------|------|
| **최고 성능 모델** | S4(전체 측정) + XGBoost (Optuna 최적화) |
| **최고 RMSE** | **0.0245 Ah** (공칭 5.0Ah 대비 오차율 0.49%) |
| **최고 R²** | **0.55** (Capacity 변동의 55% 설명) |
| **핵심 예측 피처** | `v25_voltage` (방전 종지 전압, \|r\|=0.600) |
| **저비용 최선** | S1 Stacking 앙상블 (Phase 9), RMSE=**0.0346** |
| **최고 KD 방법** | LambdaKD (Phase 10), S3 RMSE=**0.0347**, Spearman +24% |
| **기존 KD 효과** | Output KD 미미 (0.1~1.6%) → Phase 10에서 보완 성공 |

### 1.3 핵심 발견

> **배터리 용량 예측의 성능은 '모델 알고리즘' 보다 '어디까지 방전하여 측정했는가'에 의해 결정됩니다.**  
> **그러나, 피처 엔지니어링 + 앙상블 전략으로 추가 측정 없이도 S3 수준을 추월할 수 있습니다.**

- 2.5V까지 완전 방전 후 측정하면 RMSE 0.024 (R²=0.55) 달성 가능
- 4.2V 충전까지만 측정하면 RMSE 0.036 (R²=0.01) — 사실상 예측 불가
- 3.6V까지 부분 방전하면 RMSE 0.035 (R²=0.09) — 소폭 개선
- **S1 피처(3→15개 확장) + Stacking 앙상블로 RMSE 0.0346** → 추가 측정 없이 S3 Base(0.0348) 추월 (Phase 9)
- **LambdaKD(순위 기반 KD)로 Spearman +24% 개선** → 정보채널 부재를 순위 구조로 우회 (Phase 10)
- 그럼에도 Teacher(0.0245) 대비 41.5% 격차는 v25_voltage 직접 측정 없이 극복 불가

---

## 2. 데이터 탐색 및 현황 (Phase 1)

### 2.1 데이터 기본 정보

| 항목 | 내용 |
|------|------|
| **샘플 수** | 1,040개 배터리 셀 |
| **원본 피처** | 8개 (4개 측정 구간 × 전압·임피던스) |
| **타겟** | `capacity` (실제 방전 용량, Ah) |
| **결측치** | 0개 — 추가 전처리 불필요 |
| **배치** | BS-LSBAT-S240629 (동일 배치) |

### 2.2 측정 구간별 피처 설명

배터리 셀에 대해 4개 전압 조건에서 **전압(V)**과 **AC 임피던스(mΩ)**를 측정합니다:

| 측정 구간 | 전압 조건 | 의미 | 대표값 |
|-----------|----------|------|--------|
| **Initial (OCV)** | 개방회로 | 입고 시 자연 전압 | 3.456V / 11.4mΩ |
| **4.2V (Full Charge)** | 만충 상태 | 충전 완료 후 | 4.178V / 10.7mΩ |
| **3.6V (Nominal)** | 공칭 전압 부근 | 부분 방전 | 3.590V / 10.9mΩ |
| **2.5V (Cut-off)** | 방전 종지 | 완전 방전 | 2.970V / 10.8mΩ |

### 2.3 타겟 변수(Capacity) 분포

```
평균:      5.026 Ah
표준편차:  0.033 Ah  
범위:      4.792 ~ 5.097 Ah (약 6% 이내 변동)
분포형태:  왼쪽 꼬리 (일부 열화 셀이 낮은 값)
```

> **주목할 점**: Capacity의 표준편차가 0.033 Ah로 매우 작습니다. **전체 변동폭이 공칭 용량의 6% 이내**이므로, 매우 미세한 차이를 잡아내야 하는 어려운 예측 문제입니다.

### 2.4 Capacity와의 상관관계 분석

각 원본 피처의 Capacity 대비 Pearson 상관계수:

| 순위 | 피처 | Pearson r | 상관 강도 | 해석 |
|------|------|-----------|----------|------|
| 1 | `v25_voltage` | **-0.595** | 🟢 중간 | 방전 종지 전압 ↓ → 용량 ↑ |
| 2 | `v25_impedance` | -0.213 | 🟡 약함 | 방전 말기 임피던스 |
| 3 | `v42_impedance` | -0.177 | 🔴 매우 약함 | 만충 상태 임피던스 |
| 4 | `initial_impedance` | -0.150 | 🔴 매우 약함 | 초기 임피던스 |
| 5 | `initial_voltage` | +0.137 | 🔴 매우 약함 | 초기 OCV |
| 6~8 | 나머지 | \|r\| < 0.1 | 🔴 무시 가능 | 거의 상관 없음 |

> **핵심**: `v25_voltage`(방전 종지 전압)만이 유일하게 **중간 수준 이상의 상관관계**(|r|>0.5)를 보입니다. 이 피처는 **2.5V까지 완전 방전해야만** 측정 가능합니다.

### 2.5 이상치 현황

| 탐지 방법 | 결과 |
|-----------|------|
| IQR 기반 | 379개 셀(36.4%)이 1개 이상 피처에서 이상치 |
| Z-score(>3) | 극소수 (주로 v36_impedance) |
| **물리적 이상** | **1개** (v36_impedance = 1032mΩ, 정상 대비 100배) |

- IQR 이상치 비율이 36.4%로 높은 것은 분포가 좁은 피처(v42_voltage, v36_voltage)에서 과도 검출된 결과
- 대부분 **물리적으로 정상인 자연 편차**이므로 제거하지 않고 유지
- 측정 장비 오류로 판단되는 **1개 극단 이상치만 제거**

---

## 3. 파생변수 설계 (Phase 2)

원본 8개 피처의 단독 예측력이 대부분 약하므로, 배터리 도메인 지식에 기반한 **16개 파생변수**를 설계했습니다.

### 3.1 파생변수 카테고리

#### (A) 임피던스 기반 파생변수 (8개)

| 파생변수 | 수식 | 물리적 의미 |
|----------|------|------------|
| `impedance_delta_42` | Z₄.₂V − Z_initial | 충전 전후 내부저항 변화 |
| `impedance_delta_25` | Z₂.₅V − Z_initial | 방전 말기 내부저항 증가폭 |
| `impedance_delta_36` | Z₃.₆V − Z_initial | 공칭 구간 내부저항 변화 |
| `impedance_ratio_42` | Z₄.₂V / Z_initial | 충전 상태 임피던스 비율 |
| `impedance_ratio_25` | Z₂.₅V / Z_initial | 방전 상태 임피던스 비율 |
| `impedance_range` | Z_max − Z_min | 전 구간 임피던스 변동폭 |
| `impedance_mean` | mean(Z_all) | 평균 내부저항 수준 |
| `impedance_std` | std(Z_all) | 임피던스 변동성 |

**결과**: 모든 항목에서 Capacity와의 상관계수 |r| < 0.04 → **단독 선형 예측력 거의 없음**

#### (B) 전압 기반 파생변수 (5개)

| 파생변수 | 수식 | Capacity 상관(r) | 해석 |
|----------|------|-----------------|------|
| **`voltage_sag`** | V_initial − V₂.₅V | **+0.600** 🟢 | 전압 강하폭, 용량과 가장 강한 상관 |
| **`voltage_delta_42_25`** | V₄.₂V − V₂.₅V | **+0.594** 🟢 | 충방전 전압 범위 |
| `voltage_delta_initial_42` | V₄.₂V − V_initial | -0.138 | 초기→만충 전압차 |
| `voltage_delta_42_36` | V₄.₂V − V₃.₆V | -0.048 | 상위 전압 구간 강하 |
| `ocv_deviation` | V_initial − 3.6V | +0.137 | OCV 편차 |

**핵심 발견**: `voltage_sag`(r=+0.600)는 원본 최강 피처 `v25_voltage`(r=-0.595)를 **미세하게 능가**합니다!

#### (C) 복합 파생변수 (3개)

| 파생변수 | 수식 | Capacity 상관(r) |
|----------|------|-----------------|
| `power_loss_indicator` | Z₄.₂V × (V₄.₂V − V₂.₅V) | +0.250 🟡 |
| `health_index` | V₄.₂V / Z₄.₂V | +0.171 |
| `impedance_voltage_product` | Z_initial × V_initial | -0.146 |

### 3.2 파생변수 효과 요약

```
파생변수 최고 상관: voltage_sag        r=+0.600  (전압 기반)
원본피처 최고 상관: v25_voltage        r=-0.595  (2.5V 방전 측정)
                   ↑ 파생변수가 원본을 미세하게 능가

총 피처 수: 24개 (원본 8 + 파생 16)
다중공선성: |r|>0.9인 쌍 9개 → Phase 3에서 정리 필요
```

---

## 4. 데이터 전처리 및 피처 선택 (Phase 3)

### 4.1 극단 이상치 제거

- **제거 대상**: BS-LSBAT-S240629-0126 셀 1개
- **원인**: `v36_impedance` = 1,032 mΩ (정상 범위 10~12mΩ 대비 **100배** 이탈)
- **판정**: 측정 장비 오류 또는 데이터 기록 오류
- **제거 후**: 1,040개 → **1,039개** (0.1%만 제거, 데이터 손실 최소화)
- **효과**: `impedance_mean`의 Capacity 상관이 +0.013 → **-0.095**로 정상화

### 4.2 VIF(분산팽창인수) 분석

- 모든 피처의 VIF > 10: 파생변수가 원본의 선형 변환이므로 **구조적으로 불가피**
- 선형 모델에는 문제가 되지만, **트리 기반 모델(RF, XGBoost, LightGBM)은 VIF와 무관**하게 성능 발휘
- 따라서 **극단적 중복만 제거**하는 전략 채택

### 4.3 중복 피처 제거

| 제거 피처 | 유지 피처 | 제거 근거 |
|-----------|----------|----------|
| impedance_delta_42, delta_25 | impedance_ratio_42, ratio_25 | r=0.999 (동일 정보), ratio가 스케일 독립적 |
| impedance_delta_36, range, std | impedance_mean | 이상치로 왜곡, mean이 가장 해석 용이 |
| voltage_delta_42_25 | voltage_sag | r=0.991 (사실상 동일), sag가 r 미세 우위 |
| voltage_delta_42_36 | (제거) | r=-0.048, 예측 기여 없음 |

### 4.4 최종 피처셋

**총 17개 피처** = 원본 8개 + 유효 파생변수 9개:

| 카테고리 | 유지 피처 | 개수 |
|----------|----------|------|
| 원본 전압 | initial_voltage, v42_voltage, v25_voltage, v36_voltage | 4 |
| 원본 임피던스 | initial_impedance, v42_impedance, v25_impedance, v36_impedance | 4 |
| 임피던스 파생 | impedance_ratio_42, impedance_ratio_25, impedance_mean | 3 |
| 전압 파생 | voltage_delta_initial_42, voltage_sag, ocv_deviation | 3 |
| 복합 파생 | impedance_voltage_product, power_loss_indicator, health_index | 3 |

---

## 5. 측정 시나리오 설계 (Phase 3-4)

실제 공정에서의 **측정 범위(비용)**에 따라 4가지 시나리오를 정의했습니다.

### 5.1 시나리오 정의

| 시나리오 | 측정 범위 | 피처 수 | 최대 \|r\| | 측정 비용 | 소요 시간 |
|----------|----------|---------|----------|----------|----------|
| **S1** | Initial(OCV)만 | 3개 | 0.150 | 최소 | ~1분 |
| **S2** | + 4.2V 충전 | 9개 | 0.177 | 낮음 | ~30분 |
| **S3** | + 3.6V 방전 | 12개 | 0.177 | 중간 | ~1시간 |
| **S4** | + 2.5V 완전 방전 | 17개 | **0.600** | 높음 | ~2시간+ |

### 5.2 시나리오별 핵심 차이

```
S1 (Initial):  OCV + 임피던스만 → 셀 상태 간접 추정
S2 (+4.2V):    만충 후 추가 측정 → 임피던스비율, 건강지수 활용 가능
S3 (+3.6V):    부분 방전 → 평균 임피던스 추가
S4 (+2.5V):    완전 방전 → ★ v25_voltage, voltage_sag 사용 가능!
               ↑ 이 피처가 예측 성능의 핵심
```

> **S1~S3 vs S4의 결정적 차이**: S4에서만 사용 가능한 `v25_voltage`(r=-0.600)와 `voltage_sag`(r=+0.600)가 전체 예측 성능의 대부분을 결정합니다.

### 5.3 학습 데이터 분할

| 구분 | 샘플 수 | 비율 |
|------|---------|------|
| Training Set | 831개 | 80% |
| Test Set | 208개 | 20% |

- `random_state=42`로 재현성 확보
- KS 검정으로 Train/Test 분포 동질성 확인 완료
- 스케일링: 트리 모델은 미적용, 선형 모델은 RobustScaler 적용

---

## 6. 모델 학습 및 성능 비교 (Phase 5)

### 6.1 사용 모델

| 모델 | 유형 | 특성 |
|------|------|------|
| Linear Regression | 선형 | 기준선 모델 (Baseline) |
| SVR | 커널 | 비선형 패턴 포착 (RBF 커널) |
| Random Forest | 앙상블 | 배깅 기반, 과적합 방지 |
| **XGBoost** | 부스팅 | 순차 학습, 높은 예측력 |
| **LightGBM** | 부스팅 | 빠른 학습, 대규모 적합 |

### 6.2 전체 성능 결과 (4시나리오 × 5모델 = 20조합)

#### 시나리오별 최고 성능 요약

| 시나리오 | Best 모델 | RMSE | R² | MAPE | 평가 |
|----------|----------|------|-----|------|------|
| **S1** (Initial) | LinearReg | 0.0355 | 0.055 | 0.42% | ❌ 예측 불가 수준 |
| **S2** (+4.2V) | SVR | 0.0348 | 0.095 | 0.40% | ❌ 거의 무의미 |
| **S3** (+3.6V) | RandomForest | 0.0350 | 0.084 | 0.43% | ❌ 미미한 개선 |
| **S4** (전체) | **XGBoost** | **0.0246** | **0.545** | **0.25%** | ✅ 유의미한 예측 |

#### 시나리오 4 상세 결과 (모든 모델)

| 순위 | 모델 | RMSE | R² | MAPE |
|------|------|------|-----|------|
| 🥇 | **XGBoost** | **0.0246** | **0.545** | 0.25% |
| 🥈 | Random Forest | 0.0249 | 0.535 | 0.24% |
| 🥉 | SVR | 0.0260 | 0.496 | 0.27% |
| 4 | Linear Regression | 0.0262 | 0.487 | 0.29% |
| 5 | LightGBM | 0.0271 | 0.451 | 0.27% |

### 6.3 핵심 분석

#### (1) 피처셋이 모델보다 중요하다

```
S1~S3 최고 성능:  RMSE ≈ 0.035  (R² < 0.10)  → 모델 종류 무관, 예측 불가
S4 최저 성능:    RMSE = 0.027  (R² = 0.45)  → 가장 약한 모델도 S1~S3보다 우수
                                              
S4 XGBoost:     RMSE = 0.025  (R² = 0.55)  → 최고 성능
```

**결론: 어떤 최첨단 알고리즘을 사용하더라도, 2.5V 방전 측정 없이는 RMSE 0.035 이하로 내려가기 어렵습니다.**

#### (2) S1~S3의 음의 R²

- RandomForest, XGBoost가 S1~S2에서 R² < 0을 기록
- 적은 피처로 복잡한 트리 모델이 **과적합**되어 단순 평균 예측보다 못한 결과
- 이는 피처의 정보량 부족이 원인이지, 모델의 결함이 아님

#### (3) MAPE 관점

- 전 시나리오에서 MAPE 0.24~0.48% → Capacity 값 자체(5.0Ah)가 크므로 **절대 오차 대비 백분율이 작아 보임**
- RMSE(0.025~0.036)와 Capacity 표준편차(0.033)의 비율로 보는 것이 더 의미 있음

---

## 7. Knowledge Distillation 실험 (Phase 7)

### 7.1 실험 목적

S4(전체 측정)로 학습한 고성능 Teacher 모델의 **지식을 전이**하여, S2(저비용 측정)만으로도 높은 성능을 달성할 수 있는지 검증합니다.

### 7.2 실험 설계

```
Teacher Model:   XGBoost (S4, 17피처) — Optuna로 하이퍼파라미터 최적화
Student Model:   LightGBM (S2, 9피처) — 저비용 실전 모델

Distillation:    y_distilled = α × y_true + (1-α) × y_teacher_pred
                 α = 0.5 (Hard/Soft Label 동일 비중)
```

### 7.3 Optuna 하이퍼파라미터 최적화

Teacher 모델의 성능을 극대화하기 위해 Optuna로 20회 Trial을 수행했습니다:

| 파라미터 | 최적값 | 해석 |
|----------|--------|------|
| n_estimators | 653 | 충분한 앙상블 효과 |
| max_depth | 7 | 과적합-성능 균형 |
| learning_rate | 0.182 | 비교적 높은 학습률 |
| reg_lambda (L2) | 3.887 | 가중치 크기 제한 |
| subsample | 0.835 | 83.5% 데이터 사용 |

**최적화 결과**: Validation RMSE = **0.0195** (기본 대비 **20.7% 개선**)

### 7.4 KD 결과

| 모델 | 시나리오 | RMSE | R² |
|------|----------|------|-----|
| Teacher (Optuna XGBoost) | S4 (17 피처) | **0.0245** | 0.550 |
| Teacher (기본 XGBoost) | S4 (17 피처) | 0.0260 | 0.490 |
| Base Student (LightGBM) | S2 (9 피처) | 0.0363 | 0.013 |
| **Distilled Student (LightGBM+KD)** | **S2 (9 피처)** | **0.0363** | **0.015** |
| **KD 개선율** | | | **0.13%** |

### 7.5 KD 효과가 미미한 원인 분석

```
Teacher의 핵심 정보원:  v25_voltage (|r|=0.600)  ← S2에 없음!
                       voltage_sag  (|r|=0.600)  ← S2에 없음!

Student가 가진 최대 정보: v42_impedance (|r|=0.177)

정보 격차: 0.600 vs 0.177 → Teacher 지식의 대부분을 Student가 재구성 불가
```

**물리적 해석**: Teacher가 학습한 "v25_voltage와 Capacity의 관계"는 Soft Label에 인코딩되지만, Student에게는 이 패턴을 학습할 **입력 단서(피처)가 없습니다**. S2 피처(Initial+4.2V)와 v25_voltage 사이에 선형/비선형 관계가 거의 없으므로, KD의 효과가 제한됩니다.

---

## 8. 성능 고도화 실험 (Phase 8)

Phase 7의 한계를 극복하기 위해 5가지 체계적 실험을 수행했습니다.

### 8.1 실험 8-1: S3 Student KD (3.6V 추가 측정 효과)

**가설**: S3(12피처, 3.6V 추가)로 확장하면 KD 효과가 증가할 것

| 모델 | RMSE | R² | S2 대비 |
|------|------|-----|---------|
| S2 Base (9 피처) | 0.0363 | 0.013 | 기준 |
| **S3 Base (12 피처)** | **0.0348** | **0.092** | **-4.1% 개선** |
| S3 + KD (α=0.5) | 0.0351 | 0.081 | -3.5% |

**결론**: 
- S2→S3 전환으로 RMSE **4.1% 개선** (3.6V 추가 측정 효과)
- 그러나 KD 적용 시 오히려 **0.6% 악화** → S3에서도 KD 효과 없음

### 8.2 실험 8-2: α(블렌딩 비율) 그리드 탐색

**가설**: α=0.5가 아닌 최적값이 존재할 수 있음

| α 값 | S2 RMSE | S3 RMSE |
|------|---------|---------|
| 0.1 | 0.0364 | 0.0352 |
| 0.2 | 0.0365 | **0.0348** |
| 0.3 | **0.0363** | 0.0352 |
| 0.5 | 0.0364 | 0.0351 |
| 0.7 | 0.0365 | 0.0352 |
| 0.9 | 0.0366 | 0.0351 |

**결론**: S2, S3 모두 α 변화에 극히 둔감 (RMSE 변동 < 0.1%). **α 튜닝은 무의미.**

### 8.3 실험 8-3: Feature Augmentation (v25_voltage 간접 예측)

**가설**: S2 피처로 v25_voltage를 예측하는 보조 모델을 만들고, 그 예측값을 추가 피처로 사용

```
Step 1: Proxy Model (S2 피처 → v25_voltage 예측)
        LightGBM:      CV RMSE = 0.0205, Test R² = -0.0002
        XGBoost:        CV RMSE = 0.0211, Test R² = -0.0976
        RandomForest:   CV RMSE = 0.0205, Test R² = -0.0414
        
        ↑ 모든 모델 R² ≈ 0 → S2로 v25를 예측하는 것 자체가 불가능

Step 2: Augmented S2 (9 + 2 = 11 피처)
        Aug-S2 Base RMSE:  0.0360 (S2 대비 -1.0%)
        Aug-S2 + KD RMSE:  0.0360 (추가 효과 없음)
```

**결론**: v25_voltage는 S2 피처와 **정보적 연결이 없어** 예측 불가능. Feature Augmentation 전략은 **실패**.

### 8.4 실험 8-4: Semi-supervised Transfer (S4 부분 측정)

**가설**: 전체가 아닌 일부 셀만 S4(완전 방전) 측정하고, KD로 나머지에 전이

| S4 측정 비율 | Teacher RMSE | Student RMSE | S2 대비 개선 |
|-------------|-------------|-------------|-------------|
| 10% (83개) | 0.0314 | 0.0359 | +1.1% |
| **30% (249개)** | **0.0271** | **0.0357** | **+1.6%** |
| 50% (415개) | 0.0259 | 0.0366 | -0.8% |
| 70% (581개) | 0.0258 | 0.0368 | -1.3% |
| 100% (831개) | 0.0245 | 0.0360 | +0.8% |

**흥미로운 발견**: 
- Teacher 성능은 S4 비율에 비례하여 개선 (0.031→0.025)
- Student 성능은 **비단조적** — 30%에서 최적이고, 더 강한 Teacher는 오히려 악화
- **원인**: 강한 Teacher일수록 Soft Label이 S4 전용 패턴에 과적합 → S2 Student가 흡수 불가

### 8.5 실험 8-5: Optuna Student 최적화

**가설**: Student 모델 자체의 하이퍼파라미터와 α를 동시 최적화

```
50 Trials 탐색 결과:
  최적 α = 0.675 (Hard Target 비중 높음)
  Validation RMSE = 0.0233
  Test RMSE = 0.0360  → 과적합 경향
  S2 대비 개선: +0.9%
```

**결론**: Optuna로 50회 탐색해도 **0.9% 개선**에 불과. 과적합(Val 0.023 vs Test 0.036) 경향.

### 8.6 Phase 8 종합 비교

| 순위 | 모델 | 피처 수 | RMSE | R² | S2 대비 개선 |
|------|------|---------|------|-----|-------------|
| 1 | **Teacher S4 (Optuna)** | 17 | **0.0245** | **0.550** | **+32.5%** |
| 2 | S3 + KD (α=0.2) | 12 | 0.0348 | 0.095 | +4.3% |
| 3 | S3 Base | 12 | 0.0348 | 0.092 | +4.1% |
| 4 | Semi-S4 (30%) | 17 | 0.0357 | 0.044 | +1.6% |
| 5 | Aug-S2 Base | 11 | 0.0360 | 0.032 | +1.0% |
| 6 | Optuna Student | 11 | 0.0360 | 0.030 | +0.9% |
| 7 | Aug-S2 + KD | 11 | 0.0360 | 0.029 | +0.8% |
| 8 | S2 Base (기준) | 9 | 0.0363 | 0.013 | 0% |
| 9 | S2 + KD (α=0.3) | 9 | 0.0363 | 0.012 | -0.05% |

---

## 9. S1 집중 개선 실험 (Phase 9)

### 9.1 실험 목적

S1(initial_voltage, initial_impedance, ocv_deviation) **3개 피처만으로** 성능을 극대화합니다. 추가 측정 없이 입고 시점 데이터로 최선의 예측을 달성하는 것이 목표입니다.

### 9.2 실험 설계 (6단계)

| 실험 | 방법 | 핵심 아이디어 |
|------|------|-------------|
| **9-1** | 확장 피처 생성 | 다항식·비선형 변환으로 3→15 피처 확장 (MI 기준 상위) |
| **9-2** | Optuna 개별 최적화 | LGB/XGB/GB/SVR 4종 하이퍼파라미터 최적화 |
| **9-3** | Stacking 앙상블 | 7종 이기종 모델 OOF → RidgeCV Meta-learner |
| **9-4** | 확장 S1 + KD | α+HP 동시 Optuna 탐색 (80 trials), 최적 α=0.693 |
| **9-5** | Teacher-Guided Binning | KMeans 클러스터링 → Teacher 예측 평균 매핑, 최적 K=10 |
| **9-6** | 종합 비교 | 전체 모델 RMSE 비교 + 예측 vs 실제 산점도 |

### 9.3 핵심 결과

#### 9-1. 확장 피처 (3→15개)

다항식(2차 교호), log/sqrt/역수 변환 후 Mutual Information 상위 12개를 선별하여 원본 3개와 결합:

```
피처 수:   3개 → 15개
최대 |r|:  0.15 → 0.27 (+80%)
```

#### 9-3. Stacking 앙상블 (핵심 성과)

7종 이기종 모델(LGB + XGB + GradientBoosting + RF + SVR + Ridge + KNN)의 OOF(Out-of-Fold) 예측을 RidgeCV Meta-learner로 결합:

| 모델 | RMSE | R² | 비고 |
|------|------|-----|------|
| **S1 Stacking** | **0.0346** | **0.1028** | ★ 전체 S1 모델 중 최고 |
| S3 Base (비교) | 0.0348 | 0.0923 | 3.6V 추가 측정 포함 |
| S2 Base (비교) | 0.0363 | 0.0127 | 4.2V 충전 후 측정 |

> **핵심 성과: S1 Stacking(RMSE=0.0346)이 S3 Base(0.0348)를 추월!**  
> 추가 측정 없이 입고 시점 데이터만으로 3.6V 방전 측정 결과보다 우수한 예측 달성.

#### 9-4. 확장 S1 + KD

- Optuna 80 trials로 α + HP 동시 탐색
- 최적 α = 0.693 (Teacher 신호 31% 혼합)
- KD RMSE = 0.0363 → Stacking 대비 열위

#### 9-5. Teacher-Guided Binning

- KMeans(K=10)으로 S1 피처 공간을 클러스터링
- 각 클러스터에 Teacher 평균 예측값 매핑
- Binning RMSE = 0.0372 → 단순 매핑으로는 한계

### 9.4 Phase 9 종합 비교

| 순위 | 모델 | RMSE | R² | S2 대비 |
|------|------|------|-----|---------|
| 1 | **S1 Stacking** | **0.0346** | 0.103 | **+4.7%** |
| 2 | S1 확장 LGB (Optuna) | 0.0356 | 0.050 | +1.9% |
| 3 | S1 확장 XGB (Optuna) | 0.0357 | 0.045 | +1.7% |
| 4 | S1 확장 GB (Optuna) | 0.0358 | 0.040 | +1.4% |
| 5 | S1 KD (α=0.693) | 0.0363 | 0.015 | 0.0% |

---

## 10. KD 정보채널 보완 (Phase 10)

### 10.1 문제 정의

기존 Output KD는 Teacher의 **최종 예측값**만 전달합니다. 그러나 S2/S3 피처에서 v25_voltage를 재구성할 수 없으므로, Teacher가 인코딩한 v25 기반 패턴을 Student가 흡수할 **정보 채널이 부재**합니다.

Phase 10에서는 **관계·순위·경로** 3가지 대안 채널을 설계하여 이 한계를 보완합니다.

### 10.2 실험 10-1: RKD (Relational Knowledge Distillation)

**핵심 아이디어**: 개별 예측값 대신 **샘플 간 관계(거리/유사도)**를 전이

- 20개 Anchor(대표 셀) 기반 거리·유사도 피처 생성
- 2-Stage 학습: Stage 1 Base 예측 → Stage 2 관계 피처 추가 학습

| 시나리오 | Base RMSE | RKD RMSE | 개선율 |
|----------|-----------|----------|--------|
| S1 | 0.0374 | 0.0368 | +1.68% |
| S2 | 0.0363 | 0.0358 | +1.34% |
| S3 | 0.0348 | 0.0347 | +0.30% |

**결론**: Stage 1 예측 의존으로 효과 제한적. 소폭 개선만 달성.

### 10.3 실험 10-2: LambdaKD (Ranking-based KD) ★

**핵심 아이디어**: Teacher의 **순위 구조**를 보존하는 손실 함수 설계

$$L_{total} = L_{RMSE} + \lambda \cdot L_{Spearman}$$

Optuna로 λ + α + HP 동시 최적화 (60 trials/scenario):

| 시나리오 | Base RMSE | Lambda RMSE | 개선율 | Spearman ρ |
|----------|-----------|-------------|--------|------------|
| **S1** | 0.0374 | **0.0353** | **+5.64%** | 0.32 (+24%) |
| S2 | 0.0363 | 0.0359 | +1.07% | 0.28 |
| **S3** | 0.0356 | **0.0347** | **+2.49%** | 0.40 |

> **전체 KD 실험 중 최대 개선! S1에서 +5.64%, Spearman ρ 0.26→0.32 (+24%)**  
> 최적 λ = 0.41~0.70 (Teacher 순위 신호 41~70% 반영)

### 10.4 실험 10-3: Progressive Feature Bridge

**핵심 아이디어**: 중간 전압 단계를 차례로 예측하는 체인 구성

```
S2 피처 → v36_hat → v25_hat → capacity
```

| 예측 대상 | Direct r | Bridge r | 비고 |
|-----------|----------|----------|------|
| v25_voltage | 0.211 | 0.221 | 소폭 개선 |
| v25_impedance | - | 0.678 | 상당히 예측 가능 |

- Bridge-LGB RMSE = 0.0355 (S2 Base 대비 **+2.15%**)

### 10.5 Phase 10 종합 비교

| 순위 | 방법 | Best RMSE | 핵심 메트릭 |
|------|------|-----------|------------|
| 🥇 | **LambdaKD** | **S3: 0.0347** | Spearman ρ=0.40, 개선율 +2.49% |
| 🥇 | **LambdaKD** | **S1: 0.0353** | Spearman ρ=0.32, 개선율 +5.64% |
| 🥈 | Bridge-LGB | S2: 0.0355 | 단계적 경로 보완, +2.15% |
| 🥉 | RKD | S3: 0.0347 | 관계 기반 전이, +0.30% |

### 10.6 Phase 10 핵심 발견

1. **LambdaKD = 최고의 KD 보완 방법**: 순위 기반 전이로 정보 채널 부재를 우회
2. **Progressive Bridge**: 단계적 경로 예측으로 +2.15% 개선 (실용적)
3. **정보 이론적 한계 확인**: Teacher 0.0245 vs Phase 10 최고 0.0347 → **잔여 격차 41.5%는 v25_voltage 직접 측정 없이 극복 불가**

---

## 11. 종합 결론 및 제언

### 11.1 핵심 결론

#### 결론 1: 정보량의 벽 (Information Bottleneck)

배터리 용량 예측의 성능은 **"2.5V 방전 종지 전압(v25_voltage)"을 측정했는가 여부**로 결정됩니다.

```
                    ┌─────────────────────────┐
  RMSE 0.024 ──── │  S4 (v25 포함, 17 피처)   │ ←── 성능의 벽
                    └─────────────────────────┘
                              ↑ ~40% 격차 (소프트웨어로 극복 불가)
                    ┌─────────────────────────┐
  RMSE 0.035 ──── │  S2/S3 (v25 미포함)       │
                    └─────────────────────────┘
```

- **v25_voltage**의 Capacity 상관관계(|r|=0.600)가 다른 모든 피처(최대 |r|=0.177)를 압도
- KD, α 튜닝, Feature Augmentation, Optuna Student, Semi-supervised 전략을 모두 시도했으나, **1~4% 미미한 개선**에 그침
- 이는 **데이터의 물리적 한계**이며, 알고리즘으로 해결할 수 없는 문제

#### 결론 2: S1 Stacking이 비용 대비 최선

S1(입고 즉시) 3개 피처를 15개로 확장 + 7종 Stacking 앙상블로 **RMSE=0.0346**을 달성, S3 Base(0.0348)을 추월했습니다. 추가 측정 없이 최선의 예측이 가능합니다.

#### 결론 3: Knowledge Distillation의 적용 조건과 보완

기존 Output KD는 Teacher-Student 피처 간 정보 채널 부재로 효과가 미미했습니다.  
Phase 10에서 **LambdaKD(순위 기반 KD)**로 이 한계를 보완하여:
- S1: RMSE 0.0374→0.0353 (**+5.64%**), Spearman ρ +24%
- S3: RMSE 0.0356→0.0347 (**+2.49%**)
- 정보 채널이 없어도 **순위 구조 전이**로 실질적 개선 달성

### 11.2 실무 제언: 측정 전략별 경제성 분석

| 전략 | 측정 범위 | 모델 | RMSE (Ah) | 오차율 | 소요 시간 | 추천 대상 |
|------|----------|------|-----------|--------|----------|----------|
| **A. 정밀 예측** | S4 (2.5V 완전 방전) | Optuna XGBoost | 0.0245 | 0.49% | ~2시간+ | 고가 셀, 품질 인증 |
| **B. 최소 비용 최선** | S1 (입고 즉시) | Stacking 앙상블 | **0.0346** | 0.69% | ~1분 | ★ 대량 처리, 비용 최소 |
| **C. S1 + 등급 판별** | S1 (입고 즉시) | LambdaKD | 0.0353 | 0.71% | ~1분 | 등급 분류, 순위 보존 |
| **D. S3 + 순위 KD** | S3 (3.6V 부분 방전) | LambdaKD | **0.0347** | 0.69% | ~1시간 | 전체 KD 중 최고 |
| **E. S2 + 경로 보완** | S2 (4.2V 충전) | Bridge-LGB | 0.0355 | 0.71% | ~30분 | 경로 예측 활용 |
| **F. 균형 예측** | S3 (3.6V 부분 방전) | Base LightGBM | 0.0348 | 0.70% | ~1시간 | 일반 스크리닝 |

### 11.3 구체적 권고사항

#### (1) 단기 적용 (즉시 가능)

- **S1 Stacking 모델로 입고 즉시 용량 예측**: 추가 측정 없이 RMSE 0.0346 달성
- **S4 기반 XGBoost 모델로 정밀 검증**: 정확한 용량 추정이 필요한 라인에 우선 적용
- **LambdaKD로 등급 판별**: 절대 정확도보다 순위 보존이 중요한 분류 업무에 적합

#### (2) 중기 적용 (공정 최적화)

- **측정 프로토콜 이원화**:
  - 전수: S1(입고 즉시) Stacking으로 빠른 1차 스크리닝
  - 표본: S4(2.5V 방전) 측정으로 정밀 2차 검증 (전체의 10~30%)
- 1차 스크리닝에서 '의심 셀' (예측 용량이 임계값 이하)만 2차 정밀 측정

#### (3) 장기 개선 방향

- **방전 프로파일 확장**: 2.5V 단일 점이 아닌 **방전 곡선 전체**(V-t 프로파일)를 피처로 활용하면 추가 성능 향상 가능
- **EIS(전기화학 임피던스 분광법)**: 단일 주파수 AC 임피던스 대신 **다주파수 EIS 스펙트럼** 데이터를 사용하면 내부 저항의 주파수 의존성에서 추가 정보 획득
- **온도 보정**: 측정 시 온도 데이터를 함께 기록하면 온도에 의한 임피던스/전압 변동을 보정하여 예측 정확도 향상
- **배치 간 전이학습**: 현재 단일 배치(S240629) 데이터이므로, 향후 다른 배치 데이터가 축적되면 **도메인 적응(Domain Adaptation)** 기법으로 모델 범용성 확보

### 11.4 최종 요약 다이어그램

```
[측정 비용 증가 →]

S1(Initial)    S2(+4.2V)    S3(+3.6V)    S4(+2.5V)
  3 피처          9 피처         12 피처        17 피처
  R²=0.05        R²=0.01       R²=0.09       R²=0.55
  RMSE=0.036     RMSE=0.036    RMSE=0.035    RMSE=0.025
  
   ← ─ ─ ─ ─ 거의 동일 ─ ─ ─ ─ →    │← 급격한 성능 향상 →│
                                     
  ★ Phase 9: S1 Stacking RMSE=0.0346 → S3 Base 추월!
  ★ Phase 10: LambdaKD  S1=0.0353(+5.64%), S3=0.0347(+2.49%)
  ★ 핵심 피처: v25_voltage | ★ 잔여 격차: 41.5% (정보 이론적 한계)
```

---

## 12. 부록: 기술 상세

### 12.1 분석 환경

| 항목 | 버전/사양 |
|------|----------|
| Python | 3.14.2 |
| XGBoost | 3.2.0 |
| LightGBM | 4.6.0 |
| Optuna | 4.7.0 |
| scikit-learn | 1.8.0 |
| pandas | 2.3.0 |
| numpy | 2.3.0 |

### 12.2 Optuna 최적화 Teacher 모델 상세

```python
# 최적 하이퍼파라미터 (20 Trials)
{
    'n_estimators': 653,
    'max_depth': 7,
    'learning_rate': 0.182,
    'subsample': 0.835,
    'colsample_bytree': 0.810,
    'reg_alpha': 0.002,
    'reg_lambda': 3.887,
    'objective': 'reg:squarederror'
}
# Validation RMSE: 0.0195
# Test RMSE: 0.0245
```

### 12.3 Knowledge Distillation 수식

$$y_{distilled} = \alpha \cdot y_{true} + (1 - \alpha) \cdot y_{teacher}$$

- $\alpha = 1.0$: 일반 학습 (KD 없음)
- $\alpha = 0.0$: Teacher 예측만 학습
- $\alpha = 0.5$: Hard/Soft Label 동일 비중 (기본 설정)

### 12.4 시나리오별 피처 구성 상세

**S1 (INITIAL, 3피처)**: initial_voltage, initial_impedance, ocv_deviation

**S2 (INITIAL+4.2V, 9피처)**: S1 + v42_voltage, v42_impedance, impedance_ratio_42, voltage_delta_initial_42, impedance_voltage_product, health_index

**S3 (S2+3.6V, 12피처)**: S2 + v36_voltage, v36_impedance, impedance_mean

**S4 (전체, 17피처)**: S3 + v25_voltage, v25_impedance, impedance_ratio_25, voltage_sag, power_loss_indicator

### 12.5 Phase 8 실험별 상세 결과

#### 8-2. α Grid Search 결과

| α | S2 RMSE | S2 R² | S3 RMSE | S3 R² |
|---|---------|-------|---------|-------|
| 0.1 | 0.0364 | 0.009 | 0.0352 | 0.074 |
| 0.2 | 0.0365 | 0.003 | 0.0348 | 0.095 |
| 0.3 | 0.0363 | 0.012 | 0.0352 | 0.073 |
| 0.4 | 0.0365 | 0.002 | 0.0349 | 0.089 |
| 0.5 | 0.0364 | 0.006 | 0.0351 | 0.081 |
| 0.6 | 0.0365 | 0.002 | 0.0350 | 0.085 |
| 0.7 | 0.0365 | 0.004 | 0.0352 | 0.074 |
| 0.8 | 0.0365 | 0.001 | 0.0350 | 0.081 |
| 0.9 | 0.0366 | 0.000 | 0.0351 | 0.079 |

#### 8-4. Semi-supervised Transfer 비용 효율

| S4 비율 | S4 셀 수 | Teacher RMSE | Student RMSE | 비용 증가 | 성능 개선 |
|---------|---------|-------------|-------------|----------|----------|
| 0% | 0 | - | 0.0363 | 0% | 기준 |
| 10% | 83 | 0.0314 | 0.0359 | +10% | +1.1% |
| 30% | 249 | 0.0271 | 0.0357 | +30% | +1.6% |
| 50% | 415 | 0.0259 | 0.0366 | +50% | -0.8% |
| 100% | 831 | 0.0245 | 0.0360 | +100% | +0.8% |

### 12.6 Phase 9 Stacking 앙상블 구성

```python
# 7종 Base Learner
base_models = [
    ('lgb', LGBMRegressor(n_estimators=478, max_depth=6, ...)),   # Optuna 최적화
    ('xgb', XGBRegressor(n_estimators=412, max_depth=5, ...)),    # Optuna 최적화
    ('gb', GradientBoostingRegressor(n_estimators=367, ...)),     # Optuna 최적화
    ('rf', RandomForestRegressor(n_estimators=300, ...)),
    ('svr', SVR(C=1.0, epsilon=0.01)),
    ('ridge', Ridge(alpha=1.0)),
    ('knn', KNeighborsRegressor(n_neighbors=20, weights='distance'))
]
# Meta-learner: RidgeCV (5-fold OOF predictions → 억상블)
# S1 Stacking RMSE = 0.0346, R² = 0.1028
```

### 12.7 Phase 10 LambdaKD 수식

$$L_{total} = L_{RMSE} + \lambda \cdot L_{Spearman}$$

- $L_{RMSE}$: 일반 회귀 손실 (Student 예측 vs Blended Target)
- $L_{Spearman}$: Teacher 예측 순위와 Student 예측 순위 간 Spearman 상관 손실
- $\lambda$: Optuna로 최적화 (최적 0.41~0.70)
- S1 최적: λ=0.41, α=0.693, Spearman ρ=0.32
- S3 최적: λ=0.70, α=0.45, Spearman ρ=0.40

---

> **본 보고서에 대한 문의사항이 있으시면 언제든지 연락 주시기 바랍니다.**
